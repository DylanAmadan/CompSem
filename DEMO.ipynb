{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 1\n",
    "\n",
    "See REPO - https://github.com/DylanAmadan/CompSem\n",
    "See REPO for implmentation instructions\n",
    " - https://github.com/DylanAmadan/CompSem\n",
    "\n",
    "\n",
    "The first practical of the Advanced Topics in Computational Semantics course delves into the realm of learning general-purpose sentence representations within the context of natural language inference (NLI). Our objective encompasses:\n",
    "\n",
    "- Implementing four neural models to classify sentence pairs based on their relation.\n",
    "- Training these models utilizing the Stanford Natural Language Inference (SNLI) corpus (Bowman et al., 2015).\n",
    "- Evaluating the trained models using the SentEval framework (Conneau and Kiela, 2018).\n",
    "\n",
    "NLI involves discerning entailment or contradiction relationships between premises and hypotheses, a fundamental aspect of understanding language. This assignment emphasizes pretraining a sentence encoder on NLI and subsequently evaluating its efficacy on diverse natural language tasks.\n",
    "\n",
    "####Â Deliverables\n",
    "Model weights:\n",
    "https://drive.google.com/drive/folders/14oEy87KHCX-2mIeCVgAIfHWtjlFk50KL\n",
    "\n",
    "Tensorboards: \n",
    "https://drive.google.com/drive/folders/10FPdXgQOaOPjXgB0QnNdk9U3m195q9IE\n",
    "\n",
    "SNLI Analysis: Unfortunately SNLI Training was not finished at time of deadline, will upload next day.\n",
    "\n",
    "Senteval Analysis: Did not get to this part of the assignment :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have an example demonstration of the models at inference, feel free to swap out the model checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dylan/Documents/Bigold\n"
     ]
    }
   ],
   "source": [
    "cd /Users/dylan/Documents/Bigold/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (encoder): LSTM(\n",
       "    (embedding): Embedding(37179, 300, padding_idx=1)\n",
       "    (lstm): LSTM(300, 256, batch_first=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from alt_arch import LSTM, Classifier \n",
    "from data_loader import load_embeddings  \n",
    "\n",
    "# Parameters for the model (set these according to your model's training configuration)\n",
    "vocab_size = 37179  # Total number of distinct tokens in your vocabulary\n",
    "embedding_dim = 300  # Dimension of the word embeddings\n",
    "hidden_size = 256  # Number of features in the hidden state of the LSTM\n",
    "output_dim = 3  # Number of output classes (e.g., entailment, contradiction, neutral)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pretrained embeddings (make sure this matches your training setup)\n",
    "pretrained_embeddings = load_embeddings(\"Practically/data/embedding_matrix.pickle\")  # Adjust the path as needed\n",
    "\n",
    "# Initialize the encoder\n",
    "encoder = LSTM(vocab_size, embedding_dim, hidden_size, pretrained_embeddings)\n",
    "encoder.output_size = 256  # Make sure this matches the LSTM output size used during training\n",
    "\n",
    "# Initialize the Classyfer model with the correct input size for the classifier\n",
    "model = Classifier(encoder, mlp_hidden_size=512, num_classes=output_dim)\n",
    "model.to(device)\n",
    "\n",
    "# Load the model checkpoint\n",
    "checkpoint_path = \"newcheckpoints/LSTM_epoch_9.pth\"  # Adjust the path as needed\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "\n",
    "# Now the model is ready for inference or further evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     0,    12,  7319, 33135,     2, 15609,    76,  1350,   257,\n",
      "          7208,    11]])\n",
      "tensor([[    0,  9479,    35, 15609,    11]])\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import json\n",
    "\n",
    "# Define the new premise and hypothesis\n",
    "premise = \"Alicia Florrick is considering influencing a witness to win her trial.\"\n",
    "hypothesis = \"Alicia manipulates the witness.\"\n",
    "\n",
    "# Tokenize the sentences\n",
    "premise = nltk.tokenize.word_tokenize(premise)\n",
    "hypothesis = nltk.tokenize.word_tokenize(hypothesis)\n",
    "\n",
    "# Convert all tokens to lowercase\n",
    "premise = [word.lower() for word in premise]\n",
    "hypothesis = [word.lower() for word in hypothesis]\n",
    "\n",
    "# Load the vocabulary (assuming the vocabulary is already stored in a json file)\n",
    "with open(\"Practically/data/data.json\", 'r') as file:\n",
    "    vocab = json.load(file)\n",
    "\n",
    "# Assuming there is a module called data_loader with a function prep\n",
    "from data_loader import prep_example\n",
    "\n",
    "# Prepare the examples by converting tokens to indices based on the vocabulary\n",
    "premise = prep_example(premise, vocab)\n",
    "hypothesis = prep_example(hypothesis, vocab)\n",
    "\n",
    "# Output the processed data\n",
    "print(premise)\n",
    "print(hypothesis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6226, 0.1835, 0.1939]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "with torch.no_grad():  \n",
    "    output = model(premise, hypothesis)\n",
    "    probabilities = softmax(output)\n",
    "    print(probabilities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that the model gives higher probability to the first class, which refers to entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Error Analysis \n",
    "\n",
    "We conduct error analysis to identify where the models succeed and fail in predicting the entailment relationships between premises and hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  83,  452,  102,   41,   35, 1370]])\n",
      "tensor([[ 317,   12,  102,   41,   35, 3608]])\n",
      "tensor([[  2,  55,  12, 252,   2, 377]])\n",
      "tensor([[309, 383,  12, 204]])\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import json\n",
    "from Practically.data_loader import prep_example\n",
    "\n",
    "# Define initial sentences for premise and hypothesis\n",
    "premise_1 = \"Two men sitting in the sun\"\n",
    "hypothesis_1 = \"Nobody is sitting in the shade\"\n",
    "\n",
    "premise_2 = \"A man is walking a dog\"\n",
    "hypothesis_2 = \"No cat is outside\"\n",
    "\n",
    "# Tokenization of the sentences\n",
    "tokens_premise_1 = nltk.tokenize.word_tokenize(premise_1)\n",
    "tokens_hypothesis_1 = nltk.tokenize.word_tokenize(hypothesis_1)\n",
    "\n",
    "tokens_premise_2 = nltk.tokenize.word_tokenize(premise_2)\n",
    "tokens_hypothesis_2 = nltk.tokenize.word_tokenize(hypothesis_2)\n",
    "\n",
    "# Convert tokens to lowercase\n",
    "tokens_premise_1 = [token.lower() for token in tokens_premise_1]\n",
    "tokens_hypothesis_1 = [token.lower() for token in tokens_hypothesis_1]\n",
    "\n",
    "tokens_premise_2 = [token.lower() for token in tokens_premise_2]\n",
    "tokens_hypothesis_2 = [token.lower() for token in tokens_hypothesis_2]\n",
    "\n",
    "# Load vocabulary from a JSON file\n",
    "with open(\"Practically/data/data.json\", 'r') as file:\n",
    "    vocabulary = json.load(file)\n",
    "\n",
    "# Prepare examples by converting tokens to indices using the vocabulary\n",
    "indexed_premise_1 = prep_example(tokens_premise_1, vocabulary)\n",
    "indexed_hypothesis_1 = prep_example(tokens_hypothesis_1, vocabulary)\n",
    "\n",
    "indexed_premise_2 = prep_example(tokens_premise_2, vocabulary)\n",
    "indexed_hypothesis_2 = prep_example(tokens_hypothesis_2, vocabulary)\n",
    "\n",
    "# Output the processed and indexed premises and hypotheses\n",
    "print(indexed_premise_1)\n",
    "print(indexed_hypothesis_1)\n",
    "print(indexed_premise_2)\n",
    "print(indexed_hypothesis_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7491e-04, 5.1067e-03, 9.9462e-01]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "with torch.no_grad():  \n",
    "    output = model(indexed_premise_1, indexed_hypothesis_1)\n",
    "    probabilities = softmax(output)\n",
    "    print(probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.4919e-07, 7.0206e-05, 9.9993e-01]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "with torch.no_grad():  \n",
    "    output = model(indexed_premise_2, indexed_hypothesis_2)\n",
    "    probabilities = softmax(output)\n",
    "    print(probabilities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model appears to struggle with interpreting scenarios involving negation and the absence of an action or entity. For instance, in the first example, the premise \"Two men sitting in the sun\" doesn't necessarily imply that \"Nobody is sitting in the shade\". However, the model seems to interpret the presence of negation words like \"Nobody\" as indicating a contradiction. This might suggest that the model lacks a nuanced understanding of how negation interacts with different contexts to produce a neutral outcome rather than a contradiction.\n",
    "\n",
    "Similarly, the second example \"A man is walking a dog\" being related to \"No cat is outside\" presents a case where the absence mentioned in the hypothesis doesn't logically contradict the premise. The model's decision to predict a contradiction instead of a neutral response might indicate a lack of understanding of scenarios where the presence of one entity doesn't necessarily exclude the presence of another. This could be a limitation in the modelâs training where it was not exposed to enough diverse examples that specifically teach this kind of logical separation.\n",
    "\n",
    "These failures can often stem from a modelâs training data not adequately representing complex linguistic structures like negation or from an embedding layer that doesn't capture the necessary contextual cues to distinguish between unrelated statements effectively. The model may also be influenced by biases in the dataset, where the presence of certain keywords biases predictions towards contradiction.\n",
    "\n",
    "Improving the model's performance on such tasks could involve enriching the training set with more examples that challenge its understanding of context and negation, possibly incorporating synthetic data crafted to specifically address these weaknesses. Moreover, enhancing the model's architecture to better integrate broader contextual and world knowledge could also help in better predicting neutral labels in cases where the hypothesis is neither clearly entailed nor directly contradicted by the premise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further explore the hypothesis that the model may struggle with understanding negation and context-specific nuances, especially in distinguishing between neutral and contradiction labels, we can design a small set of experiments. \n",
    "\n",
    "Uno\n",
    "Objective: To assess how well the model understands negation in different contexts.\n",
    "\n",
    "Procedure: Create a set of test pairs with clear negation but varying contexts to see if the model's predictions change based on context.\n",
    "Include pairs where the negation leads to a contradiction, neutral, and entailment outcomes based on logical reasoning.\n",
    "\n",
    "Dos\n",
    "Objective: To investigate if changing the context around a negation affects model predictions.\n",
    "\n",
    "Procedure: Use the same negation in different contexts to see if the model consistently interprets the negation or if context shifts its interpretation.\n",
    "Evaluate how changes in the surrounding context influence the prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: The room was crowded.\n",
      "Hypothesis: No one was in the room.\n",
      "Probabilities: tensor([[0.0030, 0.0106, 0.9864]])\n",
      "\n",
      "Premise: The room was crowded.\n",
      "Hypothesis: No one was outside.\n",
      "Probabilities: tensor([[3.0224e-04, 1.6048e-03, 9.9809e-01]])\n",
      "\n",
      "Premise: She was alone at home.\n",
      "Hypothesis: Nobody was with her.\n",
      "Probabilities: tensor([[0.3350, 0.1502, 0.5148]])\n",
      "\n",
      "Premise: She was alone at home.\n",
      "Hypothesis: Nobody was at the park.\n",
      "Probabilities: tensor([[0.0014, 0.0402, 0.9584]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from data_loader import prep_example\n",
    "\n",
    "# Define premises and hypotheses for the experiments\n",
    "test_cases = [\n",
    "    (\"The room was crowded.\", \"No one was in the room.\"),\n",
    "    (\"The room was crowded.\", \"No one was outside.\"),\n",
    "    (\"She was alone at home.\", \"Nobody was with her.\"),\n",
    "    (\"She was alone at home.\", \"Nobody was at the park.\")\n",
    "]\n",
    "\n",
    "# Function to prepare data and make predictions\n",
    "def prepare_and_predict(premise, hypothesis):\n",
    "    # Tokenize and preprocess\n",
    "    tokens_premise = nltk.tokenize.word_tokenize(premise)\n",
    "    tokens_hypothesis = nltk.tokenize.word_tokenize(hypothesis)\n",
    "    \n",
    "    # Convert tokens to lowercase\n",
    "    tokens_premise = [token.lower() for token in tokens_premise]\n",
    "    tokens_hypothesis = [token.lower() for token in tokens_hypothesis]\n",
    "\n",
    "    # Load vocabulary from a JSON file\n",
    "    with open(\"Practically/data/data.json\", 'r') as file:\n",
    "        vocabulary = json.load(file)\n",
    "\n",
    "    # Prepare examples by converting tokens to indices using the vocabulary\n",
    "    indexed_premise = prep_example(tokens_premise, vocabulary)\n",
    "    indexed_hypothesis = prep_example(tokens_hypothesis, vocabulary)\n",
    "\n",
    "    # Use the model to predict\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    with torch.no_grad():  # Ensure no gradients are computed during inference\n",
    "        output = model(indexed_premise, indexed_hypothesis)\n",
    "        probabilities = softmax(output)\n",
    "        return probabilities\n",
    "\n",
    "# Test each case\n",
    "for premise, hypothesis in test_cases:\n",
    "    result = prepare_and_predict(premise, hypothesis)\n",
    "    print(f\"Premise: {premise}\")\n",
    "    print(f\"Hypothesis: {hypothesis}\")\n",
    "    print(\"Probabilities:\", result)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) Experiment Uno (Understanding Negation in Different Contexts):\n",
    "\n",
    "The first and second tests, involving the premise \"The room was crowded,\" examine how the model handles negation when it either directly contradicts the premise or is contextually unrelated. Both hypotheses included negations (\"No one was in the room\" and \"No one was outside\"), but their relations to the premise differed. The model incorrectly favored entailment in both cases, indicating a failure to properly handle negation that either contradicts or is unrelated to the premise. This suggests that the model may struggle to assess the logical impact of negation within the given context, favoring entailment perhaps due to training biases or limitations in its learning of contextual nuances.\n",
    "\n",
    "B) Experiment Dos (Impact of Context on Negation Interpretation):\n",
    "\n",
    "The third and fourth tests using \"She was alone at home\" further explored this by presenting negations with different contextual relevances (\"Nobody was with her\" directly supports the premise, while \"Nobody was at the park\" is contextually irrelevant). The model's predictions revealed a tendency to overlook the contextual irrelevance, as it incorrectly predicted high probabilities for entailment where neutrality was expected. This indicates issues with the model's ability to differentiate when contextual changes around a negation should alter its interpretation.\n",
    "\n",
    "From these results, it's clear that the model does exhibit the hypothesized weaknesses:\n",
    "\n",
    "- There appears to be a consistent bias toward predicting entailment when faced with negations, regardless of whether they contradict or are unrelated to the premise.\n",
    "- The model struggles with properly interpreting negation in different contexts, especially distinguishing between contradicting and unrelated scenarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ATCS2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
