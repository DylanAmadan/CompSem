#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gpus=1
#SBATCH --job-name=DeepLearningTraining
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=02:00:00
#SBATCH --output=training_output_%A.out
#SBATCH --mem=120G  # Request more memory


module purge
module load 2022
module load Anaconda3/2022.05
module load PyTorch/1.12.0-foss-2022a-CUDA-11.7.0  # Assuming PyTorch from the system module

source activate Mariia
cd $HOME/opo/Bigold

srun python -u model_train.py --encoder BiLSTM_MaxPool --session_name BiLSTM_MaxPool --epochs 10 --lr 0.01
